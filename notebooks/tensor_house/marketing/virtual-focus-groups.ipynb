{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Virtual Focus Groups Using LLMs\n",
    "\n",
    "This notebook demonstrates how to analyze user-generated content (UGC) using LLMs.\n",
    "\n",
    "#### Use Case\n",
    "We have large amounts of user-generate content such as product reviews or social media posts. We want to understand what users think about our brand, products, marketing communications, corporate social media posts, etc. Performing this analysis manually is a daunting labor-consuming task, but we can leverage language models to perform content summarization. \n",
    "\n",
    "#### Prototype: Approach and Data\n",
    "One particular way of implementing content analysis using language models is to cluster the available content in the embedding space and create a *virtual persona* (or *virtual focus group*) for each cluster that impersonates the real users and answers questions based on the psychological characteristics and traits such as values, desires, goals, interests, and lifestyle choices expressed in the content. Marketing users can perform the analysis by asking questions to such virtual personas. This simulates the analysis using real focus groups, and can also be viewed as a cost- and time-efficient alternative to using real focus groups.\n",
    "\n",
    "We use the Amazon Product Review 2018 dataset (see `datasets.md` for details) for the prototyping purposes. The prototype uses a small subset of reviews that fit the LLM context.  \n",
    "\n",
    "#### Usage and Productization\n",
    "The input dataset can be easily replaced with actual reviews or social media posts; small data schema adjustments will be required. However, the basic prompt-based summarizations will need to be replaced with a more scalable approach such as retrieval-augmented generation (RAG). In practice, the personas would be typically specified by marketing users rather than extracted from content on an ad-hoc basis."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "143c67214b039270"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#\n",
    "# Imports and helper functions\n",
    "#\n",
    "import json\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.llms import VertexAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from sklearn.cluster import KMeans\n",
    "import inspect\n",
    "\n",
    "def trim_multiline(x):\n",
    "    return inspect.cleandoc(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T14:37:28.791147Z",
     "start_time": "2023-12-10T14:37:27.439978Z"
    }
   },
   "id": "d10f1fe5eb1ef8a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the Review Data\n",
    "\n",
    "In this section, we load the product and review data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e4c99ce1f50c12e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 574628 reviews\n",
      "Loaded 12299 products\n"
     ]
    }
   ],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  df = {}\n",
    "  for i, d in enumerate(parse(path)):\n",
    "    df[i] = d\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "base_path = '<<path to data>>' # Replace with the path to the Amazon Review Data folder\n",
    "review_df = getDF(base_path + 'Luxury_Beauty.json.gz')\n",
    "print(f\"Loaded {len(review_df)} reviews\")\n",
    "\n",
    "meta_df = getDF(base_path + 'meta_Luxury_Beauty.json.gz')\n",
    "print(f\"Loaded {len(meta_df)} products\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T14:37:42.121191Z",
     "start_time": "2023-12-10T14:37:30.908694Z"
    }
   },
   "id": "e746762cf0509275"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Personas By Clustering Review Embeddings\n",
    "\n",
    "In this section, we compute embeddings for individual reviews, cluster the reviews in the embedding space to create the data foundations for virtual personas, and then identify the personas by analyzing the content in each cluster. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "717c51e8a54d4593"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following embedding model: project=None location='us-central1' request_parallelism=5 max_retries=6 stop=None model_name='textembedding-gecko' client=<vertexai.language_models.TextEmbeddingModel object at 0x7f92ede23880> client_preview=None temperature=0.0 max_output_tokens=128 top_p=0.95 top_k=40 credentials=None n=1 streaming=False\n",
      "Using the following generative model: \u001B[1mVertexAI\u001B[0m\n",
      "Params: {'model_name': 'text-bison', 'temperature': 0.7, 'max_output_tokens': 128, 'candidate_count': 1, 'top_k': 40, 'top_p': 0.95}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Initialize LLM provider\n",
    "# (google-cloud-aiplatform must be installed)\n",
    "#\n",
    "from google.cloud import aiplatform\n",
    "aiplatform.init(\n",
    "    project='gd-gcp-rnd-genai-convai',\n",
    "    location='us-central1'\n",
    ")\n",
    "embedding_llm = VertexAIEmbeddings()\n",
    "print(f'Using the following embedding model: {embedding_llm}')\n",
    "\n",
    "llm = VertexAI(temperature=0.7)\n",
    "print(f'Using the following generative model: {llm}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:22:11.174482Z",
     "start_time": "2023-12-10T15:22:09.898262Z"
    }
   },
   "id": "2643c5fc3d043ad1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 4733 reviews for 173 products.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Sample and filter the reviews \n",
    "#\n",
    "n_products = 200\n",
    "meta_sample_df = meta_df.sample(n_products)\n",
    "df = pd.merge(meta_sample_df[['asin', 'title']], \n",
    "              review_df[['asin', 'reviewerName', 'summary', 'reviewText']], \n",
    "              how='inner', on='asin')\n",
    "\n",
    "df[['summary', 'reviewText']] = df[['summary', 'reviewText']].astype(str)\n",
    "df = df[(df['summary'].map(len) > 10) & (df['reviewText'].map(len) > 100)]   # Filter out too short reviews\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Sampled {df.shape[0]} reviews for {df['asin'].nunique()} products\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T14:40:35.230379Z",
     "start_time": "2023-12-10T14:40:34.942218Z"
    }
   },
   "id": "9afca0ea3cf518a5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 4733 embedding vectors\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Compute embeddings for the reviews\n",
    "#\n",
    "def row_to_document(row):\n",
    "    return trim_multiline(f\"\"\"\n",
    "    Product title: {row[\"title\"]}\n",
    "    Review summary: {row[\"summary\"]}\n",
    "    Review text: {row[\"reviewText\"]}\"\"\")\n",
    "\n",
    "docs = df.apply(lambda review: row_to_document(review), axis=1).to_list()\n",
    "\n",
    "embeddings = embedding_llm.embed_documents(docs)\n",
    "print(f'Computed {len(embeddings)} embedding vectors')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T14:52:52.249313Z",
     "start_time": "2023-12-10T14:49:49.835910Z"
    }
   },
   "id": "a27897ea86f1242e"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following 4 personas have been identified:\n",
      "{0: ' The Sophisticated Beauty Connoisseur',\n",
      " 1: ' The Versatile Hair Enthusiast',\n",
      " 2: ' The Refined Grooming Enthusiast',\n",
      " 3: ' The Skincare Enthusiast'}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Perform clustering and attribute each review with the cluster ID\n",
    "#\n",
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=\"auto\").fit(embeddings)\n",
    "clustered_df = pd.concat([df, pd.DataFrame(kmeans.labels_, columns=['cluster_id'])], axis=1)\n",
    "\n",
    "#\n",
    "# Analyze each cluster and create a persona title\n",
    "#\n",
    "topic_prompt = \"\"\"You're an expert marketing analyst. Your goal is to read of bunch of product reviews and create a title for an imaginary persona who wrote these reviews. \n",
    "The title should clearly describe the psychological characteristics and traits such as values, desires, goals, interests, and lifestyle choices. \n",
    "The title MUST NOT contain any formatting or personal names. \n",
    "\n",
    "---------------------------\n",
    "PRODUCT REVIEWS:\n",
    "{reviews}\n",
    "---------------------------\n",
    "\n",
    "\n",
    "\n",
    "PERSONA TITLE:\n",
    "\"\"\"\n",
    "topic_prompt_template = PromptTemplate(template=topic_prompt, input_variables=[\"reviews\"])\n",
    "\n",
    "n_samples_per_cluster = 50\n",
    "sampled_reviews_df = clustered_df.groupby('cluster_id').sample(n=n_samples_per_cluster)\n",
    "personas = {}\n",
    "for cluster_id in range(n_clusters):\n",
    "    reviews_in_cluster = sampled_reviews_df[sampled_reviews_df['cluster_id']==cluster_id].apply(\n",
    "        lambda review: row_to_document(review), axis=1).to_list()\n",
    "\n",
    "    response = llm(topic_prompt_template.format(reviews=\"\\n\\n\\n\".join(reviews_in_cluster)))\n",
    "    personas[cluster_id] = response\n",
    "\n",
    "print(f'The following {len(personas)} personas have been identified:')\n",
    "pprint(personas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:24:46.514183Z",
     "start_time": "2023-12-10T15:24:38.423768Z"
    }
   },
   "id": "7fbe713c876e2cf4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ask Questions to Virtual Personas\n",
    "\n",
    "In this section, we demonstrate how business users (e.g. marketing analysts) can interact with the virtual personas and get insights into customers' perception of the brand, product, and messaging."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de67594456a7175b"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To improve the products, I would recommend the following:\n",
      "\n",
      "**For Baxter of California Comb:**\n",
      "- Improve packaging to ensure combs arrive in good condition.\n",
      "- Consider offering a case or pouch for the comb to protect it when not in use.\n",
      "\n",
      "**For Billy Jealousy Beard Envy Kit:**\n",
      "- Improve the quality control process to ensure products are not damaged or defective before shipping.\n",
      "- Soften the bristles of the brush to make it more gentle on the beard.\n",
      "- Consider adding a leave-in conditioner to the kit to help soften and condition the beard.\n",
      "\n",
      "**For Clarisonic Sensitive Facial Cleansing Brush Head Replacement\n"
     ]
    }
   ],
   "source": [
    "persona_prompt = \"\"\"You're a virtual persona defined as {persona_title}. Please answer the question consistently with your previous product reviews. \n",
    "Your answer must be consistent with your reviews in terms of values, desires, goals, interests, lifestyle choices, and product strengths and weaknesses which you have noticed.\n",
    "\n",
    "YOUR PREVIOUS REVIEWS:\n",
    "{reviews}\n",
    "\n",
    "---------------------------\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "persona_prompt_template = PromptTemplate(template=persona_prompt, input_variables=[\"persona_title\", \"reviews\", \"question\"])\n",
    "\n",
    "cluster_id = 2\n",
    "persona_reviews = sampled_reviews_df[sampled_reviews_df['cluster_id']==cluster_id].apply(\n",
    "        lambda review: row_to_document(review), axis=1)\n",
    "person_review_as_text = \"\\n\\n\".join(persona_reviews)\n",
    "\n",
    "question = \"How you would recommend to improve the products?\"\n",
    "\n",
    "response = llm(persona_prompt_template.format(persona_title=personas[cluster_id], reviews=person_review_as_text, question=question))\n",
    "\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:35:57.979443Z",
     "start_time": "2023-12-10T18:35:53.658940Z"
    }
   },
   "id": "1eea98a2b9dd7b3a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py310",
   "language": "python",
   "display_name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
